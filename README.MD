# 멜 스펙트로그램 전처리 정리

> “데이터셋을 전처리해서, 음성에서 멜 스펙트로그램을 뽑을 때  
>  **시간축 `T`는 어떻게 생기고**,  
>  **세로로 80개 특징(멜 채널)을 어떻게 만드는지**”에 대한 정리

---

## 1. 전체 파이프라인 한 줄 정리

1. **원시 음성(waveform)** 준비 (예: 16kHz, mono)
2. 음성을 **짧은 프레임 단위로 자르기** → 이때 프레임 개수가 곧 `T`
3. 각 프레임마다 **STFT(Short-Time Fourier Transform)** 계산
4. 주파수 축을 **Mel 필터뱅크(80개 필터)** 로 압축 → 세로 80차원
5. (옵션) log, 정규화 등 추가 전처리

결과적으로 나오는 멜 스펙트로그램의 기본 형태는 보통:

- `(T, 80)`  또는  
- `(80, T)`  (프레임 수 × 멜 빈 수)

딥러닝 프레임워크에서는 여기에 `batch` / `channel` 축을 더 붙여서:

- PyTorch conv2d 기준: `(B, 1, 80, T)`

이런 식으로 씀.

---

## 2. 파형에서 시간축 `T` 만들기 (프레임 나누기)

### 2.1. 기본 설정

- 샘플링 레이트: `sr` (예: 22050 Hz)
- 윈도우 크기: `n_fft` (예: 1024 샘플 ≈ 46ms)
- hop length(프레임 간 간격): `hop_length` (예: 256 샘플 ≈ 11.6ms)

원시 음성 `x` 가 길이 `N` 샘플이면,  
프레임 개수 `T`는 대략:

\[
T \approx \left\lfloor \frac{N - n\_fft}{\text{hop\_length}} \right\rfloor + 1
\]

즉:

- 음성을 **슬라이딩 윈도우**로 잘라가면서
- 한 윈도우(프레임)마다 스펙트럼을 계산
- 그렇게 나온 프레임들의 **개수**가 곧 멜 스펙트로그램의 **시간축 `T`**

### 2.2. 그림으로 생각하면

- 가로축: 시간 → 프레임 0, 1, 2, …, T-1
- 세로축: 주파수/멜 특징 → 밑에서 80개로 만듦
